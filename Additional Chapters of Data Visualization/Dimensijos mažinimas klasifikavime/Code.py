# -*- coding: utf-8 -*-
"""Klasifikavimas_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bbqiYnyZYEfHclslir4Jts2mkQW2sFd3
"""

import pandas as pd
import numpy as np
from sklearn.manifold import MDS
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus
from sklearn.model_selection import GridSearchCV, KFold, PredefinedSplit
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from IPython.display import Image
import graphviz
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import ComplementNB
from sklearn.preprocessing import MinMaxScaler
import sklearn.metrics as metrics

"""# 1. Pradinė duomenų analizė"""

!pip install graphviz
!pip install pydotplus

import pandas as pd
import numpy as np
from sklearn.manifold import MDS
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus
from sklearn.model_selection import GridSearchCV, KFold, PredefinedSplit
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from IPython.display import Image
import graphviz
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

df = pd.read_excel("be_nuliu.xlsx")
df_dim = df.copy() # kopija dimensijos mazinimui
df_dim.insert(0, 'ID', range(1, 1 + len(df_dim))) # pridedam id kiekvienam pacientui, reikes dimensijos mazinimui

# Tikrinam ar aibe subalansuota
print(df["Outcome"].value_counts()) # subalansuota

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies",	"Glucose",	"BloodPressure",	"SkinThickness",	"Insulin",	"BMI",	"DiabetesPedigreeFunction",	"Age"]
X=df[feature_cols]
y=df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

#Duomenu normavimas pagal min-max
def min_max_norm(x):
  return(x - x.min())/ (x.max() - x.min())

X_train = min_max_norm(X_train) # po viena karta leisti

# testavimo aibes normavimas pagal mokymo aibe
def min_max_norm_test(x):
  return(x - X_train.min())/ (X_train.max() - X_train.min())

X_test = min_max_norm_test(X_test) # viena karta leisti
X_test = pd.DataFrame(X_test, columns=X_test.columns)

"""# 2. Sprendimų medis

## Visos kovariantės

### By default
"""

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(random_state=0)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
#gaunamas 56.16% tikslumas

#Confusion matrix

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

y_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

params = {
    'max_depth':  [4,5,6],
    'max_features': [0.4, 0.6, 0.8],
    'min_samples_split': [5,10,15]
}

grid_search = GridSearchCV(
    estimator=DecisionTreeClassifier(random_state=0),
    param_grid=params,
    cv=5,
)

grid_search.fit(X_train, y_train)
print("Geriausi parametrai: ",grid_search.best_params_)

# geriausi parametrai
{
    'max_depth': 4,
    'max_features': 0.6,
    'min_samples_split': 5
}
#tikslumas gaunasi 65.75%

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
# #tikslumas gaunasi 65.75%

#Confusion matrix

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
fy_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### Keičiant hiperparametrus"""

# keiciant hiperparametrus
results = pd.DataFrame(grid_search.cv_results_)

results.to_csv("results.csv", sep=',', index=False, encoding='utf-8')


# parodome kelias pirmas eilutes
print("Detali išklotinė: ")
display(results)

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 5, random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 10, random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 15, random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.8, min_samples_split = 15, random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=6, max_features=0.6, min_samples_split = 15, random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""## Reikšmingos kovariantės

"""

# Issirenkam reiksmingas kovariantes
#Nėštumas
#Gliukozė
#KMI
#Diabeto f-ja
df = pd.read_excel("be_nuliu.xlsx")
df_r = df[["Pregnancies", "Glucose", "BMI","DiabetesPedigreeFunction"]]

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies","Glucose",	"BMI",	"DiabetesPedigreeFunction"]
X=df[feature_cols]
y=df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

X_train = min_max_norm(X_train) # po viena karta leisti

X_test = min_max_norm_test(X_test) # viena karta leisti
X_test = pd.DataFrame(X_test, columns=X_test.columns)

"""### By Default

"""

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(random_state=0)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
#gaunamas 34.25% tikslumas

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
fy_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

params = {
    'max_depth':  [4,5,6],
    'max_features': [0.4, 0.6, 0.8],
    'min_samples_split': [5,10,15]
}

grid_search = GridSearchCV(
    estimator=DecisionTreeClassifier(random_state=0),
    param_grid=params,
    cv=5,
)

grid_search.fit(X_train, y_train)
print("Geriausi parametrai: ",grid_search.best_params_)

clf = DecisionTreeClassifier(max_depth=5, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
# #tikslumas gaunasi 36.99%

#Confusion matrix

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### Keičiant hiperparametrus"""

# keiciant hiperparametrus
results = pd.DataFrame(grid_search.cv_results_)

results.to_csv("results_r.csv", sep=',', index=False, encoding='utf-8')


# parodome kelias pirmas eilutes
print("Detali išklotinė: ")
display(results)

clf = DecisionTreeClassifier(max_depth=5, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=5, max_features=0.4, min_samples_split = 10,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 15,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 10,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 15,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""## Sumazintos dimensijos"""

df = pd.read_excel("be_nuliu.xlsx")
df_dim = df.copy() # kopija dimensijos mazinimui
df_dim.insert(0, 'ID', range(1, 1 + len(df_dim))) # pridedam id kiekvienam pacientui, reikes dimensijos mazinimui

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies",	"Glucose",	"BloodPressure",	"SkinThickness",	"Insulin",	"BMI",	"DiabetesPedigreeFunction",	"Age"]
X=df_dim[feature_cols]
y=df_dim["Outcome"]



X_norm = min_max_norm(X) # po viena karta leisti


from sklearn.metrics import pairwise_distances
distance_data=pairwise_distances(X_norm, metric="euclidean")
mds = MDS(random_state=0)
dim_data = pd.DataFrame(mds.fit_transform(distance_data))


X_train, X_test, y_train, y_test = train_test_split(dim_data, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

"""### By Default"""

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(random_state=0)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
#gaunamas 63% tikslumas

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
fy_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

params = {
    'max_depth':  [4,5,6],
    'max_features': [0.4, 0.6, 0.8],
    'min_samples_split': [5,10,15]
}

grid_search = GridSearchCV(
    estimator=DecisionTreeClassifier(random_state=0),
    param_grid=params,
    cv=5,
)

grid_search.fit(X_train, y_train)
print("Geriausi parametrai: ",grid_search.best_params_)

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
# #tikslumas gaunasi 69.49%

print(confusion_matrix(y_test, y_pred))
# Calculate the accuracy
#acc = accuracy_score(y_test, y_pred)

# Calculate the precision
#prec = precision_score(y_test, y_pred)

# Calculate the recall
#recall = recall_score(y_test, y_pred)

# Calculate the f1 score
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
sens = tp / (tp + fn)
spec = tn / (tn+fp)
NPV = tn / (tn+fn)
prec = tp / (tp+fp)
acc = (tp + tn) / (tp +fn+tn+fp)

# Print the results
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", sens)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
fy_pred_proba = clf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

from matplotlib.colors import ListedColormap
import numpy as np

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
X_set, y_set = X_test, y_test
X_set = np.array(X_set)
y_set = np.array(y_set)
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, clf.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('lightgreen', 'xkcd:light violet')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('green', 'violet'))(i), label = j, edgecolors='black')

plt.xlabel('Dim 1')
plt.ylabel('Dim 2')
plt.legend()
plt.show()

"""### Keičiant hiperparametrus"""

# keiciant hiperparametrus
results = pd.DataFrame(grid_search.cv_results_)

results.to_csv("results_d.csv", sep=',', index=False, encoding='utf-8')


# parodome kelias pirmas eilutes
print("Detali išklotinė: ")
display(results)

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 10,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.6, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 10,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = DecisionTreeClassifier(max_depth=4, max_features=0.8, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""# 3. Atsitiktinis medis

## Visos kovariantes

### By default
"""

# https://www.datacamp.com/tutorial/random-forests-classifier-python
# https://medium.com/analytics-vidhya/random-forest-classifier-and-its-hyperparameters-8467bec755f6

# Create Random Forest Classifier
rf = RandomForestClassifier()

# Train Random forest classifier
rf.fit(X_train, y_train)

# Predict the response for test data
y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

print("Klasifikavimo tikslumas: {:.2f}".format(rf.score(X_test, y_test)))
# Klasifikavimo tikslumas: 0.53

y_pred = rf.predict(X_test)
print("Rizika nenaudojant score funkcijos: {:.2f}".format(np.mean(y_pred != y_test)))
# Rizika: 0.47

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

y_pred_proba = rf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

param_grid = {
    'max_depth':  [10, 15, 20, 25, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,5,10,15],
    'n_estimators': [60, 75, 100]
}

rf = GridSearchCV(
    estimator=RandomForestClassifier(),
    param_grid=param_grid,
    cv=5,
)

rf.fit(X_train, y_train)
print(rf.best_params_)

# (max_depth=25, max_features=0.5, n_estimators=100, min_samples_split=15,random_state=57)

rf_param = RandomForestClassifier(max_depth=25, max_features=0.5, n_estimators=100, min_samples_split=15,random_state=57)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

# Tikslumas 53.42465753424658

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

# [[52 44]
#  [24 26]]
# Accuracy: 0.5342465753424658
# Precision: 0.37142857142857144
# Recall(Sensitivity): 0.52
# F1 Score: 0.43333333333333335
# Specificity: 0.5416666666666666
# Negative Predictive Value:  0.6842105263157895

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

results_rf = pd.DataFrame(rf.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf_best = RandomForestClassifier(max_depth=30, max_features=0.4, n_estimators=75, min_samples_split=2, random_state=78)
rf_best.fit(X_train, y_train)
y_pred = rf_best.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

"""### RandomizedSearchCV"""

param_grid = {
    'max_depth':  [10, 15, 20, 25, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,5,10,15],
    'n_estimators': [60, 75, 100],
    'random_state': [50, 123, 5]
}
# Create a random forest classifier
rf = RandomForestClassifier()

# Use random search to find the best hyperparameters
rand_search = RandomizedSearchCV(rf,
                                 param_distributions = param_grid,
                                 n_iter=10,
                                 cv=5)

# Fit the random search object to the data
rand_search.fit(X_train, y_train)

# Create a variable for the best model
best_rf = rand_search.best_estimator_

# Print the best hyperparameters
print('Best hyperparameters:',  rand_search.best_params_)

# Best hyperparameters: {'random_state': 123, 'n_estimators': 75, 'min_samples_split': 10, 'max_features': 0.6, 'max_depth': 20}

rf_param = RandomForestClassifier(random_state=123, n_estimators=75, min_samples_split=10, max_features=0.6, max_depth=20)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

# Tikslumas 53.42465753424658

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

# [[52 44]
#  [24 26]]
# Accuracy: 0.5342465753424658
# Precision: 0.37142857142857144
# Recall(Sensitivity): 0.52
# F1 Score: 0.43333333333333335
# Specificity: 0.5416666666666666
# Negative Predictive Value:  0.6842105263157895

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

correct_predictions = np.array(y_test) == np.array(y_pred)

plt.scatter(range(len(y_test)), y_test, c=correct_predictions, cmap='coolwarm')
plt.scatter(range(len(y_pred)), y_pred, marker='x', color='black')
plt.xlabel('Sample Index')
plt.ylabel('Class')
plt.title('Correctly and Incorrectly Predicted Values')
plt.xticks(range(len(y_test)))
plt.yticks([0, 1])
plt.legend(['Correct', 'Incorrect'])
plt.show()

results_rf = pd.DataFrame(rand_search.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf = RandomForestClassifier(random_state=123, n_estimators=75, min_samples_split=5, max_features=0.4, max_depth=15)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

"""## Reiksmingos kovariantes"""

# Issirenkam reiksmingas kovariantes
#Nėštumas
#Gliukozė
#KMI
#Diabeto f-ja
df = pd.read_excel("be_nuliu.xlsx")
df_r = df[["Pregnancies", "Glucose", "BMI","DiabetesPedigreeFunction"]]

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies","Glucose",	"BMI",	"DiabetesPedigreeFunction"]
X=df[feature_cols]
y=df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

X_train = min_max_norm(X_train) # po viena karta leisti

X_test = min_max_norm_test(X_test) # viena karta leisti
X_test = pd.DataFrame(X_test, columns=X_test.columns)

"""### By default"""

# Create Random Forest Classifier
rf = RandomForestClassifier()

# Train Random forest classifier
rf.fit(X_train, y_train)

# Predict the response for test data
y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

y_pred_proba = rf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

param_grid = {
    'max_depth':  [10, 20, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,10,15],
    'n_estimators': [60, 75, 100],
    'random_state': [50, 123, 5]
}

rf = GridSearchCV(
    estimator=RandomForestClassifier(),
    param_grid=param_grid,
    cv=5,
)

rf.fit(X_train, y_train)
print(rf.best_params_)

# {'max_depth': 10, 'max_features': 0.4, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 123}

rf_param = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=100, min_samples_split=2,random_state=123)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

results_rf = pd.DataFrame(rf.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf_best = RandomForestClassifier(max_depth=30, max_features=0.5, n_estimators=60, min_samples_split=15,random_state=50)
rf_best.fit(X_train, y_train)
y_pred = rf_best.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

"""### RandomisedSearchCV"""

param_grid = {
    'max_depth':  [10, 15, 20, 25, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,5,10,15],
    'n_estimators': [60, 75, 100],
    'random_state': [50, 123, 5]
}

rf = RandomForestClassifier()
rand_search = RandomizedSearchCV(rf,
                                 param_distributions = param_grid,
                                 n_iter=10,
                                 cv=5)

rand_search.fit(X_train, y_train)

# Create a variable for the best model
best_rf = rand_search.best_estimator_

# Print the best hyperparameters
print('Best hyperparameters:',  rand_search.best_params_)

# Best hyperparameters: {'random_state': 123, 'n_estimators': 100, 'min_samples_split': 5, 'max_features': 0.5, 'max_depth': 25}

rf = RandomForestClassifier(random_state=123, n_estimators=100, min_samples_split=5, max_features=0.5, max_depth=25)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

results_rf = pd.DataFrame(rand_search.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf_best = RandomForestClassifier(random_state=50, n_estimators=100, min_samples_split=2, max_features=0.4, max_depth=25)
rf_best.fit(X_train, y_train)
y_pred = rf_best.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)
print(confusion_matrix(y_test, y_pred))

"""## Sumazintos dimensijos"""

df = pd.read_excel("be_nuliu.xlsx")
df_dim = df.copy() # kopija dimensijos mazinimui
df_dim.insert(0, 'ID', range(1, 1 + len(df_dim))) # pridedam id kiekvienam pacientui, reikes dimensijos mazinimui

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies",	"Glucose",	"BloodPressure",	"SkinThickness",	"Insulin",	"BMI",	"DiabetesPedigreeFunction",	"Age"]
X=df_dim[feature_cols]
y=df_dim["Outcome"]



X_norm = min_max_norm(X) # po viena karta leisti


from sklearn.metrics import pairwise_distances
distance_data=pairwise_distances(X_norm, metric="euclidean")
mds = MDS(random_state=0)
dim_data = pd.DataFrame(mds.fit_transform(distance_data))


X_train, X_test, y_train, y_test = train_test_split(dim_data, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

"""### By default"""

# Create Random Forest Classifier
rf = RandomForestClassifier()

# Train Random forest classifier
rf.fit(X_train, y_train)

# Predict the response for test data
y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

# Accuracy: 65.75342465753424

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

# [[96  0]
#  [50  0]]
# Accuracy: 0.6575342465753424
# Precision: 0.0
# Recall(Sensitivity): 0.0
# F1 Score: 0.0
# Specificity: 1.0
# Negative Predictive Value:  0.6575342465753424

y_pred_proba = rf.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

"""### GridSearchCV"""

param_grid = {
    'max_depth':  [10, 20, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,10,15],
    'n_estimators': [60, 75, 100],
    'random_state': [50, 123, 5]
}

rf = GridSearchCV(
    estimator=RandomForestClassifier(),
    param_grid=param_grid,
    cv=5,
)

rf.fit(X_train, y_train)
print(rf.best_params_)

# {'max_depth': 10, 'max_features': 0.4, 'min_samples_split': 10, 'n_estimators': 75, 'random_state': 5}

rf_param = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=75, min_samples_split=10,random_state=5)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

# Accuracy: 65.75342465753424

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

# [[96  0]
#  [50  0]]
# Accuracy: 0.6575342465753424
# Precision: 0.0
# Recall(Sensitivity): 0.0
# F1 Score: 0.0
# Specificity: 1.0
# Negative Predictive Value:  0.6575342465753424

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

from matplotlib.colors import ListedColormap
import numpy as np

rf = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=60, min_samples_split=2,random_state=50)
rf.fit(X_train, y_train)
X_set, y_set = X_test, y_test
X_set = np.array(X_set)
y_set = np.array(y_set)
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, rf.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('lightgreen', 'xkcd:light violet')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('green', 'violet'))(i), label = j, edgecolors='black')

plt.xlabel('Dim 1')
plt.ylabel('Dim 2')
plt.legend()
plt.show()

results_rf = pd.DataFrame(rf.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf_best = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=60, min_samples_split=10,random_state=5)
rf_best.fit(X_train, y_train)
y_pred = rf_best.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

from matplotlib.colors import ListedColormap
import numpy as np

rf_param = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=75, min_samples_split=10,random_state=5)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)
X_set, y_set = X_test, y_test
X_set = np.array(X_set)
y_set = np.array(y_set)
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, clf.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('lightgreen', 'xkcd:light violet')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('green', 'violet'))(i), label = j, edgecolors='black')

plt.xlabel('Dim 1')
plt.ylabel('Dim 2')
plt.legend()
plt.show()

"""### RandomizedSearchCV"""

param_grid = {
    'max_depth':  [10, 15, 20, 25, 30],
    'max_features': [0.4, 0.5, 0.6],
    'min_samples_split': [2,5,10,15],
    'n_estimators': [60, 75, 100],
    'random_state': [50, 123, 5]
}

rf = RandomForestClassifier()
rand_search = RandomizedSearchCV(rf,
                                 param_distributions = param_grid,
                                 n_iter=10,
                                 cv=5)

rand_search.fit(X_train, y_train)

# Create a variable for the best model
best_rf = rand_search.best_estimator_

# Print the best hyperparameters
print('Best hyperparameters:',  rand_search.best_params_)

# Best hyperparameters: {'random_state': 50, 'n_estimators': 100, 'min_samples_split': 10, 'max_features': 0.6, 'max_depth': 25}

rf = RandomForestClassifier(random_state=50, n_estimators=100, min_samples_split=10, max_features=0.6, max_depth=25)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)

# Accuracy: 65.75342465753424

print(confusion_matrix(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
spec = tn / (tn+fp)
NPV = tn / (tn+fn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall(Sensitivity):", recall)
print("F1 Score:", f1)
print("Specificity:", spec)
print("Negative Predictive Value: ", NPV)

# [[96  0]
#  [50  0]]
# Accuracy: 0.6575342465753424
# Precision: 0.0
# Recall(Sensitivity): 0.0
# F1 Score: 0.0
# Specificity: 1.0
# Negative Predictive Value:  0.6575342465753424

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.title('ROC kreivė')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

results_rf = pd.DataFrame(rand_search.cv_results_).sort_values(by='rank_test_score')
results_rf.head()

rf_best = RandomForestClassifier(random_state=50, n_estimators=100, min_samples_split=2, max_features=0.5, max_depth=20)
rf_best.fit(X_train, y_train)
y_pred = rf_best.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)*100
print("Accuracy:", accuracy)
print(confusion_matrix(y_test, y_pred))

"""# 3. Naiviojo Bajeso klasifikatorius

"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from mlxtend.plotting import plot_confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import ComplementNB
from sklearn.preprocessing import MinMaxScaler

"""## Visos kovariantes

"""

df = pd.read_excel("be_nuliu.xlsx")

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies",	"Glucose",	"BloodPressure",	"SkinThickness",	"Insulin",	"BMI",	"DiabetesPedigreeFunction",	"Age"]
X=df[feature_cols]
y=df["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

#Duomenu normavimas pagal min-max
def min_max_norm(x):
  return(x - x.min())/ (x.max() - x.min())

X_train = min_max_norm(X_train) # po viena karta leisti

# testavimo aibes normavimas pagal mokymo aibe
def min_max_norm_test(x):
  return(x - X_train.min())/ (X_train.max() - X_train.min())

X_test = min_max_norm_test(X_test) # viena karta leisti
X_test = pd.DataFrame(X_test, columns=X_test.columns)

"""### Gauso Bajeso metodas. Neturi reguliuojamu parametru."""

#apmokome ir ivertiname rizika ir tiksluma
gauso_nb_8 = GaussianNB()
gauso_nb_8.fit(X_train,y_train)

# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-gauso_nb_8.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(gauso_nb_8.score(X_test, y_test)))

#ivertinsime tiksluma
y_pred_gauso_8 = gauso_nb_8.predict(X_test)

# Calculate the confusion matrix
conf_matrix_gauso_8 = confusion_matrix(y_true=y_test, y_pred=y_pred_gauso_8)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_gauso_8, fp_gauso_8, fn_gauso_8, tp_gauso_8 = conf_matrix_gauso_8.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_gauso_8)
print("True Negative (TN): ", tn_gauso_8)
print("False Positive (FP): ", fp_gauso_8)
print("False Negative (FN): ", fn_gauso_8)

# Calculate accuracy
accuracy_gauso_8 = (tp_gauso_8 + tn_gauso_8) / (tp_gauso_8 + tn_gauso_8 + fp_gauso_8 + fn_gauso_8)

# Calculate precision
precision_gauso_8 = tp_gauso_8 / (tp_gauso_8 + fp_gauso_8)

# Calculate recall
recall_gauso_8 = tp_gauso_8 / (tp_gauso_8 + fn_gauso_8)

# Calculate F1-score
f1_score_gauso_8 = 2 * (precision_gauso_8 * recall_gauso_8) / (precision_gauso_8 + recall_gauso_8)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_gauso_8, 2))
print("Precision: ", round(precision_gauso_8, 2))
print("Recall: ", round(recall_gauso_8, 2))
print("F1-score: ", round(f1_score_gauso_8, 2))

#padarome grafika

fig, ax = plot_confusion_matrix(conf_mat=conf_matrix_gauso_8, figsize=(6, 6), cmap=plt.cm.Greens,
                                show_normed=True, colorbar=True)
plt.rcParams.update({'font.size': 16, 'text.color' : 'black', 'axes.labelcolor':'black'})
plt.xlabel('Prognozuoti', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""Rezultatai blogi, neatpazista sveiku pacientu.

#### Braizysime ROC
"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )

# calculate the fpr and tpr for all thresholds of the classification
fpr_gauso_8 , tpr_gauso_8 , threshold_gauso_8  = metrics.roc_curve(y_test, y_pred_gauso_8 )
roc_auc_gauso_8  = metrics.auc(fpr_gauso_8 , tpr_gauso_8)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_gauso_8 , tpr_gauso_8 , 'b', label = 'AUC = %0.2f' % roc_auc_gauso_8 )
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""### Daugialypis Naiviojo Bajeso metodas. Reguliuojami parametrai:


*   Alpha (Additive (Laplace/Lidstone) smoothing parameter )
*   force_alpha (If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.)

*   fit_prior (Whether to learn class prior probabilities or not. If false, a uniform prior will be used.)





"""

par_grid = {'alpha': [0,0.05, 0.1, 0.15, 0.2, 0.25, 0.3],'force_alpha': [True, False], 'fit_prior':[True, False]}

grid_search_daugialypisnb = GridSearchCV(estimator=MultinomialNB(), param_grid=par_grid, cv=5)

# renkame geriausią parametrų kombinaciją panaudodami fit metodą
grid_search_daugialypisnb.fit(X_train, y_train)

# geriausių hiperparametrų rinkinys
print("Geriausi parametrai: {}".format(grid_search_daugialypisnb.best_params_))

#optimalios hipotezės, atitinkančios parinktas parametrų reikšmes, rizika (best_score grąžina
# teisingai klasifikuotų stebinių dažnio įvertį, t.y. 1-rizika)
print("Geriausios h rizika apmokymo-validavimo aibėje: {}".format(1-grid_search_daugialypisnb.best_score_))

#geriausia hipotezė
h = grid_search_daugialypisnb .best_estimator_
print("Geriausia hipotezė: {}".format(h))

# 5.4) detali viso proceso išklotinė
results = pd.DataFrame(grid_search_daugialypisnb.cv_results_)

# parodome kelias pirmas eilutes
print("Detali išklotinė:")
display(results.head(30))

# Geriausios hipotezės rizikos vertinimas
print("Geriausios h rizika testinėje aibėje: {}".format(1-h.score(X_test, y_test)))

"""Su keliais rinkiniais islieka toks pat geriausias rezultatas, masina teigia, jog geriausias yra {'alpha': 0, 'fit_prior': True, 'force_alpha': True}"""

#ivertinsime tiksluma
daugialypis_8=MultinomialNB(alpha = 0, fit_prior=True, force_alpha=True)
daugialypis_8.fit(X_train,y_train)
y_pred_daugialypis_8 = daugialypis_8.predict(X_test)

# Calculate the confusion matrix
conf_matrix_daugialypis_8 = confusion_matrix(y_true=y_test, y_pred=y_pred_daugialypis_8)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_daugialypis_8, fp_daugialypis_8, fn_daugialypis_8, tp_daugialypis_8 = conf_matrix_daugialypis_8.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_daugialypis_8)
print("True Negative (TN): ", tn_daugialypis_8)
print("False Positive (FP): ", fp_daugialypis_8)
print("False Negative (FN): ", fn_daugialypis_8)

# Calculate accuracy
accuracy_daugialypis_8 = (tp_daugialypis_8 + tn_daugialypis_8) / (tp_daugialypis_8 + tn_daugialypis_8 + fp_daugialypis_8 + fn_daugialypis_8)

# Calculate precision
precision_daugialypis_8 = tp_daugialypis_8 / (tp_daugialypis_8 + fp_daugialypis_8)

# Calculate recall
recall_daugialypis_8 = tp_daugialypis_8 / (tp_daugialypis_8 + fn_daugialypis_8)

# Calculate F1-score
f1_score_daugialypis_8 = 2 * (precision_daugialypis_8 * recall_daugialypis_8) / (precision_daugialypis_8 + recall_daugialypis_8)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_daugialypis_8, 2))
print("Precision: ", round(precision_daugialypis_8, 2))
print("Recall: ", round(recall_daugialypis_8, 2))
print("F1-score: ", round(f1_score_daugialypis_8, 2))

# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-daugialypis_8.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(daugialypis_8.score(X_test, y_test)))

#padarome grafika
from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_daugialypis_8)
disp.plot(cmap = 'Greens')
plt.xlabel('Prognozuoti', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""Bendras accuraccy tik 50 rpoc. testavimo aibei

#### Braizome ROC
"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )
fpr_daugialypis_8 , tpr_daugialypis_8 , threshold_daugialypis_8  = metrics.roc_curve(y_test, y_pred_daugialypis_8)
roc_auc_daugialypis_8  = metrics.auc(fpr_daugialypis_8 , tpr_daugialypis_8)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_daugialypis_8 , tpr_daugialypis_8 , 'b', label = 'AUC = %0.2f' % roc_auc_daugialypis_8)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""### Pilnasis Naiviojo Bajeso metodas. Reguliuojami parametrai:


*   Alpha (Additive (Laplace/Lidstone) smoothing parameter )
*   force_alpha (If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.)

"""

par_grid = {'alpha': [0, 0.1, 0.2,  0.3, 0.4, 0.45,0.5,0.55, 0.6, 0.7, 0.8, 0.9, 1],'force_alpha': [True, False]}

grid_search_pilnasis_8 = GridSearchCV(estimator=ComplementNB(), param_grid=par_grid, cv=5)

# renkame geriausią parametrų kombinaciją panaudodami fit metodą
grid_search_pilnasis_8.fit(X_train, y_train)

# geriausių hiperparametrų rinkinys
print("Geriausi parametrai: {}".format(grid_search_pilnasis_8.best_params_))

#optimalios hipotezės, atitinkančios parinktas parametrų reikšmes, rizika (best_score grąžina
# teisingai klasifikuotų stebinių dažnio įvertį, t.y. 1-rizika)
print("Geriausios h rizika apmokymo-validavimo aibėje: {}".format(1-grid_search_pilnasis_8.best_score_))

#geriausia hipotezė
h = grid_search_pilnasis_8.best_estimator_
print("Geriausia hipotezė: {}".format(h))

# 5.4) detali viso proceso išklotinė

results = pd.DataFrame(grid_search_pilnasis_8.cv_results_)

# parodome kelias pirmas eilutes
print("Detali išklotinė:")
display(results.head(15))

# Geriausios hipotezės rizikos vertinimas
print("Geriausios h rizika testinėje aibėje: {}".format(1-h.score(X_test, y_test)))

pilnasis_8=ComplementNB(alpha=0.45, force_alpha=True)
pilnasis_8.fit(X_train,y_train)
y_pred_pilnasis_8 = pilnasis_8.predict(X_test)

# Calculate the confusion matrix
conf_matrix_pilnasis_8 = confusion_matrix(y_true=y_test, y_pred=y_pred_pilnasis_8)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_pilnasis_8, fp_pilnasis_8, fn_pilnasis_8, tp_pilnasis_8 = conf_matrix_pilnasis_8.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_pilnasis_8)
print("True Negative (TN): ", tn_pilnasis_8)
print("False Positive (FP): ", fp_pilnasis_8)
print("False Negative (FN): ", fn_pilnasis_8)

# Calculate accuracy
accuracy_pilnasis_8 = (tp_pilnasis_8 + tn_pilnasis_8) / (tp_pilnasis_8 + tn_pilnasis_8 + fp_pilnasis_8 + fn_pilnasis_8)

# Calculate precision
precision_pilnasis_8 = tp_pilnasis_8 / (tp_pilnasis_8 + fp_pilnasis_8)

# Calculate recall
recall_pilnasis_8 = tp_pilnasis_8 / (tp_pilnasis_8 + fn_pilnasis_8)

# Calculate F1-score
f1_score_pilnasis_8 = 2 * (precision_pilnasis_8 * recall_pilnasis_8) / (precision_pilnasis_8 + recall_pilnasis_8)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_pilnasis_8, 2))
print("Precision: ", round(precision_pilnasis_8, 2))
print("Recall: ", round(recall_pilnasis_8, 2))
print("F1-score: ", round(f1_score_pilnasis_8, 2))

print("Klasifikatoriaus rizika: {:.2f}".format(1-pilnasis_8.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(pilnasis_8.score(X_test, y_test)))

#padarome grafika

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_pilnasis_8)
disp.plot(cmap = 'Greens')
plt.xlabel('Prognozuoti', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""Nei vienas neparode geru rezultatu.
tikslumas testavimo aibei 0.49

#### Braizome ROC
"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )
fpr_pilnasis_8 , tpr_pilnasis_8 , threshold_pilnasis_8  = metrics.roc_curve(y_test, y_pred_pilnasis_8)
roc_auc_pilnasis_8  = metrics.auc(fpr_pilnasis_8 , tpr_pilnasis_8)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_pilnasis_8, tpr_pilnasis_8, 'b', label = 'AUC = %0.2f' % roc_auc_pilnasis_8)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""## su reiksmingomis kovariantemis"""

# Issirenkam reiksmingas kovariantes
#Nėštumas
#Gliukozė
#KMI
#Diabeto f-ja
df = pd.read_excel("be_nuliu.xlsx")
df_r = df[["Pregnancies", "Glucose", "BMI","DiabetesPedigreeFunction"]]

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies","Glucose",	"BMI",	"DiabetesPedigreeFunction"]
X=df[feature_cols]
y=df["Outcome"]
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

X_train = min_max_norm(X_train) # po viena karta leisti

X_test = min_max_norm_test(X_test) # viena karta leisti
X_test = pd.DataFrame(X_test, columns=X_test.columns)

"""### Gauso Bajeso metodas. Neturi reguliuojamu parametru."""

#apmokome ir ivertiname rizika ir tiksluma
gauso_4 = GaussianNB()
gauso_4.fit(X_train,y_train)

# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-gauso_4.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(gauso_4.score(X_test, y_test)))

gauso_4.fit(X_train,y_train)
y_pred_gauso_4 = gauso_4.predict(X_test)

# Calculate the confusion matrix
conf_matrix_gauso_4 = confusion_matrix(y_true=y_test, y_pred=y_pred_gauso_4)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_gauso_4, fp_gauso_4, fn_gauso_4, tp_gauso_4 = conf_matrix_gauso_4.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_gauso_4)
print("True Negative (TN): ", tn_gauso_4)
print("False Positive (FP): ", fp_gauso_4)
print("False Negative (FN): ", fn_gauso_4)

# Calculate accuracy
accuracy_gauso_4 = (tp_gauso_4 + tn_gauso_4) / (tp_gauso_4 + tn_gauso_4 + fp_gauso_4 + fn_gauso_4)

# Calculate precision
precision_gauso_4 = tp_gauso_4 / (tp_gauso_4 + fp_gauso_4)

# Calculate recall
recall_gauso_4 = tp_gauso_4 / (tp_gauso_4 + fn_gauso_4)

# Calculate F1-score
f1_score_gauso_4 = 2 * (precision_gauso_4 * recall_gauso_4) / (precision_gauso_4 + recall_gauso_4)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_gauso_4, 2))
print("Precision: ", round(precision_gauso_4, 2))
print("Recall: ", round(recall_gauso_4, 2))
print("F1-score: ", round(f1_score_gauso_4, 2))

fig, ax = plot_confusion_matrix(conf_mat=conf_matrix_gauso_4, figsize=(6, 6), cmap=plt.cm.Greens,
                                show_normed=True,colorbar=True)
plt.rcParams.update({'font.size': 16, 'text.color' : 'black', 'axes.labelcolor':'black'})
plt.xlabel('Prognozuoti', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""nera gero rezultato

#### Braizome ROC
"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )
fpr_gauso_4 , tpr_gauso_4 , threshold_gauso_4  = metrics.roc_curve(y_test, y_pred_gauso_4)
roc_auc_gauso_4  = metrics.auc(fpr_gauso_4, tpr_gauso_4)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_gauso_4, tpr_gauso_4, 'b', label = 'AUC = %0.2f' % roc_auc_gauso_4)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""### Daugialypis Naiviojo Bajeso metodas. Reguliuojami parametrai:


*   Alpha (Additive (Laplace/Lidstone) smoothing parameter )
*   force_alpha (If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.)

*   fit_prior (Whether to learn class prior probabilities or not. If false, a uniform prior will be used.)

"""

par_grid = {'alpha': [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1],'force_alpha': [True, False], 'fit_prior':[True, False]}

grid_search_daugialypisnb = GridSearchCV(estimator=MultinomialNB(), param_grid=par_grid, cv=5)

# renkame geriausią parametrų kombinaciją panaudodami fit metodą
grid_search_daugialypisnb .fit(X_train, y_train)

# geriausių hiperparametrų rinkinys
print("Geriausi parametrai: {}".format(grid_search_daugialypisnb.best_params_))

#optimalios hipotezės, atitinkančios parinktas parametrų reikšmes, rizika (best_score grąžina
# teisingai klasifikuotų stebinių dažnio įvertį, t.y. 1-rizika)
print("Geriausios h rizika apmokymo-validavimo aibėje: {}".format(1-grid_search_daugialypisnb.best_score_))

#geriausia hipotezė
h = grid_search_daugialypisnb .best_estimator_
print("Geriausia hipotezė: {}".format(h))
print('Parametrai tiesiogiai:{}'.format(h.get_params()))

# 5.4) detali viso proceso išklotinė

# atributas cv_results_ grąžina dictionary struktūrą;
# patogumo dėlei konvertuojame į DataFrame
results = pd.DataFrame(grid_search_daugialypisnb.cv_results_)

# parodome kelias pirmas eilutes
print("Detali išklotinė:")
display(results.head(30))

# Geriausios hipotezės rizikos vertinimas
print("Geriausios h rizika testinėje aibėje: {}".format(1-h.score(X_test, y_test)))

daugialypis_4=MultinomialNB(alpha=0, force_alpha=True)
daugialypis_4.fit(X_train,y_train)
y_pred_daugialypis_4 = daugialypis_4.predict(X_test)

# Calculate the confusion matrix
conf_matrix_daugialypis_4 = confusion_matrix(y_true=y_test, y_pred=y_pred_daugialypis_4)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_daugialypis_4, fp_daugialypis_4, fn_daugialypis_4, tp_daugialypis_4 = conf_matrix_daugialypis_4.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_daugialypis_4)
print("True Negative (TN): ", tn_daugialypis_4)
print("False Positive (FP): ", fp_daugialypis_4)
print("False Negative (FN): ", fn_daugialypis_4)

# Calculate accuracy
accuracy_daugialypis_4 = (tp_daugialypis_4 + tn_daugialypis_4) / (tp_daugialypis_4 + tn_daugialypis_4 + fp_daugialypis_4 + fn_daugialypis_4)

# Calculate precision
precision_daugialypis_4 = tp_daugialypis_4 / (tp_daugialypis_4 + fp_daugialypis_4)

# Calculate recall
recall_daugialypis_4 = tp_daugialypis_4 / (tp_daugialypis_4 + fn_daugialypis_4)

# Calculate F1-score
f1_score_daugialypis_4 = 2 * (precision_daugialypis_4 * recall_daugialypis_4) / (precision_daugialypis_4 + recall_daugialypis_4)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_daugialypis_4, 2))
print("Precision: ", round(precision_daugialypis_4, 2))
print("Recall: ", round(recall_daugialypis_4, 2))
print("F1-score: ", round(f1_score_daugialypis_4, 2))

# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-daugialypis_4.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(daugialypis_4.score(X_test, y_test)))

#padarome grafika

fig, ax = plot_confusion_matrix(conf_mat=conf_matrix_daugialypis_4,figsize=(6, 6),
                                cmap=plt.cm.Greens, show_normed=True, colorbar=True)
plt.xlabel('Prognozavo', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""####Braizome ROC"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )
fpr_daugialypis_4 , tpr_daugialypis_4 , threshold_daugialypis_4  = metrics.roc_curve(y_test, y_pred_daugialypis_4)
roc_auc_daugialypis_4 = metrics.auc(fpr_daugialypis_4, tpr_daugialypis_4)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_daugialypis_4, tpr_daugialypis_4, 'b', label = 'AUC = %0.2f' % roc_auc_daugialypis_4)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""### Pilnasis Naiviojo Bajeso metodas. Reguliuojami parametrai:


*   Alpha (Additive (Laplace/Lidstone) smoothing parameter )
*   force_alpha (If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.)

"""

par_grid = {'alpha': [0, 0.1, 0.2,  0.3, 0.4, 0.45,0.5,0.55, 0.6, 0.7, 0.8, 0.9, 1],'force_alpha': [True, False]}

grid_search_pilnasisnb = GridSearchCV(estimator=ComplementNB(), param_grid=par_grid, cv=5)

# renkame geriausią parametrų kombinaciją panaudodami fit metodą
grid_search_pilnasisnb.fit(X_train, y_train)

# geriausių hiperparametrų rinkinys
print("Geriausi parametrai: {}".format(grid_search_pilnasisnb.best_params_))

#optimalios hipotezės, atitinkančios parinktas parametrų reikšmes, rizika (best_score grąžina
# teisingai klasifikuotų stebinių dažnio įvertį, t.y. 1-rizika)
print("Geriausios h rizika apmokymo-validavimo aibėje: {}".format(1-grid_search_pilnasisnb.best_score_))

#geriausia hipotezė
h = grid_search_pilnasisnb.best_estimator_
print("Geriausia hipotezė: {}".format(h))
print('Parametrai tiesiogiai:{}'.format(h.get_params()))

# 5.4) detali viso proceso išklotinė

results = pd.DataFrame(grid_search_pilnasisnb.cv_results_)

# parodome kelias pirmas eilutes
print("Detali išklotinė:")
display(results.head(100))

# Geriausios hipotezės rizikos vertinimas
print("Geriausios h rizika testinėje aibėje: {}".format(1-h.score(X_test, y_test)))

pilnasis_4=ComplementNB(alpha=1, force_alpha=True)
pilnasis_4.fit(X_train,y_train)
y_pred_pilnasis_4 = pilnasis_4.predict(X_test)

# Calculate the confusion matrix
conf_matrix_pilnasis_4 = confusion_matrix(y_true=y_test, y_pred=y_pred_pilnasis_4)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_pilnasis_4, fp_pilnasis_4, fn_pilnasis_4, tp_pilnasis_4 = conf_matrix_pilnasis_4.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_pilnasis_4)
print("True Negative (TN): ", tn_pilnasis_4)
print("False Positive (FP): ", fp_pilnasis_4)
print("False Negative (FN): ", fn_pilnasis_4)

# Calculate accuracy
accuracy_pilnasis_4 = (tp_pilnasis_4 + tn_pilnasis_4) / (tp_pilnasis_4 + tn_pilnasis_4 + fp_pilnasis_4 + fn_pilnasis_4)

# Calculate precision
precision_pilnasis_4 = tp_pilnasis_4 / (tp_pilnasis_4 + fp_pilnasis_4)

# Calculate recall
recall_pilnasis_4 = tp_pilnasis_4 / (tp_pilnasis_4 + fn_pilnasis_4)

# Calculate F1-score
f1_score_pilnasis_4 = 2 * (precision_pilnasis_4 * recall_pilnasis_4) / (precision_pilnasis_4 + recall_pilnasis_4)
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_pilnasis_4, 2))
print("Precision: ", round(precision_pilnasis_4, 2))
print("Recall: ", round(recall_pilnasis_4, 2))
print("F1-score: ", round(f1_score_pilnasis_4, 2))
# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-pilnasis_4.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(pilnasis_4.score(X_test, y_test)))

#padarome grafika

fig, ax = plot_confusion_matrix(conf_mat=conf_matrix_pilnasis_4,figsize=(6, 6),
                                cmap=plt.cm.Greens, show_normed=True, colorbar=True)
plt.xlabel('Prognozavo', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""#### Braizome ROC"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )
fpr_pilnasis_4 , tpr_pilnasis_4 , threshold_pilnasis_4  = metrics.roc_curve(y_test, y_pred_pilnasis_4)
roc_auc_pilnasis_4 = metrics.auc(fpr_pilnasis_4, tpr_pilnasis_4)

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_pilnasis_4, tpr_pilnasis_4, 'b', label = 'AUC = %0.2f' % roc_auc_pilnasis_4)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""## sumazintos dimensijos"""

df = pd.read_excel("be_nuliu.xlsx")
df_dim = df.copy() # kopija dimensijos mazinimui
df_dim.insert(0, 'ID', range(1, 1 + len(df_dim))) # pridedam id kiekvienam pacientui, reikes dimensijos mazinimui

# padaliname aibę į apmokymo ir testavimo imtis skirdami 80 proc. apmokymui ir 20 proc. testavimo
feature_cols = ["Pregnancies",	"Glucose",	"BloodPressure",	"SkinThickness",	"Insulin",	"BMI",	"DiabetesPedigreeFunction",	"Age"]
X=df_dim[feature_cols]
y=df_dim["Outcome"]

X_norm = min_max_norm(X) # po viena karta leisti

from sklearn.metrics import pairwise_distances
distance_data=pairwise_distances(X_norm, metric="euclidean")
mds = MDS(random_state=0)
dim_data = pd.DataFrame(mds.fit_transform(distance_data))

X_train, X_test, y_train, y_test = train_test_split(dim_data, y, random_state=0, train_size=0.8, shuffle=True, stratify=y)

"""### Gauso Bajeso metodas. Neturi reguliuojamu parametru."""

#apmokome ir ivertiname rizika ir tiksluma
gauso_2 = GaussianNB()
gauso_2.fit(X_train,y_train)

# įvertiname modelio riziką (atitinkančią 0-1 nuostolių funkciją) panaudodami testavimo imtį
print("Klasifikatoriaus rizika: {:.2f}".format(1-gauso_2.score(X_test, y_test)))

# score funkcija grąžina teisingai suklasifikuotų stebinių dalį
print("Klasifikavimo tikslumas: {:.2f}".format(gauso_2.score(X_test, y_test)))

gauso_2.fit(X_train,y_train)
y_pred_gauso_2 = gauso_2.predict(X_test)

# Calculate the confusion matrix
conf_matrix_gauso_2 = confusion_matrix(y_true=y_test, y_pred=y_pred_gauso_2)

# Extract the true positive, true negative, false positive, and false negative values from the confusion matrix
tn_gauso_2 , fp_gauso_2 , fn_gauso_2 , tp_gauso_2  = conf_matrix_gauso_2.ravel()

# Print the true positive, true negative, false positive, and false negative values
print("True Positive (TP): ", tp_gauso_2 )
print("True Negative (TN): ", tn_gauso_2 )
print("False Positive (FP): ", fp_gauso_2 )
print("False Negative (FN): ", fn_gauso_2 )

# Calculate accuracy
accuracy_gauso_2  = (tp_gauso_2  + tn_gauso_2 ) / (tp_gauso_2  + tn_gauso_2  + fp_gauso_2  + fn_gauso_2 )

# Calculate precision
precision_gauso_2  = tp_gauso_2  / (tp_gauso_2  + fp_gauso_2 )

# Calculate recall
recall_gauso_2  = tp_gauso_2  / (tp_gauso_2  + fn_gauso_2 )

# Calculate F1-score
f1_score_gauso_2  = 2 * (precision_gauso_2  * recall_gauso_2 ) / (precision_gauso_2  + recall_gauso_2 )
# Print the accuracy, precision, recall, and F1-score
print("\n\nMetrics:")
print("Accuracy: ", round(accuracy_gauso_2 , 2))
print("Precision: ", round(precision_gauso_2 , 2))
print("Recall: ", round(recall_gauso_2 , 2))
print("F1-score: ", round(f1_score_gauso_2 , 2))

#padarome grafika
from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_gauso_2 )
disp.plot(cmap = 'Greens')
plt.xlabel('Prognozuoti', fontsize=18)
plt.ylabel('Tikri', fontsize=18)
plt.title('Sumaišymo matrica', fontsize=18)
plt.show()

"""#### Braizome ROC"""

#suskaiciuojame reikalingus parametrus roc kreivei, t. y. jautruma (true positive rate) ir 1-specifiskuma (False positive rate )

# calculate the fpr and tpr for all thresholds of the classification
fpr_gauso_2 , tpr_gauso_2 , threshold_gauso_2  = metrics.roc_curve(y_test, y_pred_gauso_2 )
roc_auc_gauso_2  = metrics.auc(fpr_gauso_2 , tpr_gauso_2)
roc_auc_gauso_2

#braizome roc
plt.title('ROC kreivė')
plt.plot(fpr_gauso_2 , tpr_gauso_2 , 'b', label = 'AUC = %0.2f' % roc_auc_gauso_2 )
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""#### Ziurime, kaip sis metodas suklasifikavo"""

from matplotlib.colors import ListedColormap
import numpy as np

X_set, y_set = X_test, y_test
X_set = np.array(X_set)
y_set = np.array(y_set)
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, gauso_2.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('lightgreen', 'xkcd:light violet')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())

for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('green', 'violet'))(i), label = j, edgecolors='black')

plt.xlabel('Dim 1')
plt.ylabel('Dim 2')
plt.legend()
plt.show()

#sukuriame tuscius listus
row_num_klaidingi_vienetai=[]
row_num_klaidingi_nuliai=[]

#suskaiciuojame,  kurie butent nesutapo ir paemame ju indeksus
for i in range(len(y_test)):
  if y_test.iloc[i] != y_pred_gauso_2[i]:
    if(y_test.iloc[i]==0):
      row_num_klaidingi_vienetai.append(y_test.index[i])
    if(y_test.iloc[i]==1):
      row_num_klaidingi_nuliai.append( y_test.index[i])

#atspausdiname indeksus
print(row_num_klaidingi_vienetai)#is tikruju nuliai
print(row_num_klaidingi_nuliai)#is tikruju vienetai

#aprasomoji statistika
X.iloc[row_num_klaidingi_vienetai].describe()

#aprasomoji statistika
X.iloc[row_num_klaidingi_nuliai].describe()

"""## Braizome bendra bajeso roc kreives"""

plt.title(' Naiviojo Bajeso klasifikatorių ROC kreivės')
plt.plot(fpr_gauso_2 , tpr_gauso_2 , 'b', label = 'Gauso (dim = 2) AUC = %0.2f' % roc_auc_gauso_2 )
plt.plot(fpr_gauso_4 , tpr_gauso_4 , 'g', label = 'Kitais atvejais AUC = %0.2f' % roc_auc_gauso_4 )
plt.legend(loc = 'lower right', fontsize="small")
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()

"""## Braizome visas bendras roc kreives"""

rf_param = RandomForestClassifier(max_depth=10, max_features=0.4, n_estimators=75, min_samples_split=10,random_state=5)
rf_param.fit(X_train, y_train)
y_pred = rf_param.predict(X_test)

y_pred_proba = rf_param.predict_proba(X_test)[::,1]
fpr_random_forest, tpr_random_forest, _ = metrics.roc_curve(y_test, y_pred_proba)
auc_random_forest = metrics.roc_auc_score(y_test, y_pred_proba)

clf = DecisionTreeClassifier(max_depth=4, max_features=0.4, min_samples_split = 5,random_state=0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

y_pred = clf.predict(X_test)
fy_pred_proba = clf.predict_proba(X_test)[::,1]
fpr_tree, tpr_tree, _ = metrics.roc_curve(y_test, y_pred_proba)
auc_tree = metrics.roc_auc_score(y_test, y_pred_proba)

plt.title('Geriausių klasifikatorių ROC kreivės')
plt.plot(fpr_gauso_2 , tpr_gauso_2 , 'b', label = 'Gauso (dim = 2) AUC = %0.2f' % roc_auc_gauso_2 )
plt.plot(fpr_random_forest , tpr_random_forest , 'r', label = 'Atsitiktinio miško ir sprendimų \nmedžio(dim = 2) AUC = %0.2f' % auc_random_forest )
plt.legend(loc = 'lower right', fontsize="small")
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('Jautrumas')
plt.xlabel('1 - specifiškumas')
plt.show()