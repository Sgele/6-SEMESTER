# -*- coding: utf-8 -*-
"""Neigiamas_binominis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VNQ2fv1xFF05ErEa3ixVwhopr1N2oldp
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.sparse import csr_matrix
import statsmodels.api as sm
import seaborn as sns
from matplotlib import pyplot as plt
from patsy import dmatrices
import math
import statistics
from yellowbrick.regressor import CooksDistance
from statsmodels.stats.outliers_influence import variance_inflation_factor
from patsy import dmatrices
from statsmodels.formula.api import ols

df = pd.read_excel("train_data_2lab.xlsx")

# perkoduojami kintamieji
cleanup_nums = {"gender":     {"male": 1, "female": 0},
                "married": {"yes": 0, "no": 1}}
df = df.replace(cleanup_nums)

# paleist tik viena karta nes kitaip klaida ir TIK BOXPLOTAMS
df1 = df
df1['prestige'] = pd.cut(df1['prestige'], bins=[0, 3, float('Inf')], labels=['<=3', '>3'])
df1['mentor'] = pd.cut(df1['mentor'], bins=[0, 10, 20, 30, 40, 50, 60, float('Inf')], labels=['[0;10)', '[10;20)','[20;30)','[30;40)','[40;50)','[50;60)','[60;70)'])

# boxplotai

fig, axs = plt.subplots(3, 2, figsize=(20, 17), sharey=True)
sns.boxplot(ax = axs[0, 0], data = df1, x="gender", y="articles")
axs[0,0].set_title("Articles by gender")
sns.boxplot(ax = axs[0, 1], data = df1, x = "married", y = "articles")
axs[0,1].set_title("Articles by marital status")
sns.boxplot(ax = axs[1, 0], data = df1, x="kids", y="articles")
axs[1,0].set_title("Articles by number of kids")
sns.boxplot(ax = axs[1, 1], data = df1, x="prestige", y="articles")
axs[1,1].set_title("Articles by prestige level")
sns.boxplot(ax = axs[2, 0], data = df1, x="mentor", y="articles")
axs[2,0].set_title("Articles by mentors")

# histograma

sns.histplot(data=df, x = "articles").set(title='Histogram. Published articles')
mean = statistics.mean(df["articles"])
var = statistics.pvariance(df["articles"])
print("Mean of published articles: ", round(mean, 2))
print("Variance of published articles: ", round(var, 2))

# keiciami kintamuju tipai
df["gender"] = df["gender"].astype('category')
df["married"] = df["married"].astype('category')

print(df.dtypes)

expr = """articles ~ gender + married + kids + prestige + mentor"""
y_train, X_train = dmatrices(expr, df, return_type = "dataframe")
poisson_training_results = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()
print(poisson_training_results.summary())

# overdispersion testas

round(poisson_training_results.pearson_chi2 / poisson_training_results.df_resid, 2)

# ISSKIRTYS - kuko matas
x = df[['gender',	'married',	'kids',	'prestige',	'mentor']]
y = df['articles']

# Instantiate and fit the visualizer
visualizer = CooksDistance()
visualizer.fit(x, y)
visualizer.show()

# multikolinearumo patikrinimui

M = ['gender',	'married',	'kids',	'prestige',	'mentor', 'articles']


corr_matrix = df.loc[:,M].corr()
print(corr_matrix)




y, X = dmatrices('articles ~ gender +married + kids + prestige + mentor', data=df, return_type='dataframe')

vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif["features"] = X.columns
vif.round(2)

# multikolinearumo nera, nes nevirsijo 4

#DFBetai
X_train = df[['gender',	'married',	'kids',	'prestige',	'mentor']]
Y_train = df['articles']


#Model statistics
model1 = sm.OLS(Y_train, sm.add_constant(X_train)).fit()
print_model1 = model1.summary()
print(print_model1)

influence = model1.get_influence()
pd.Series(influence.hat_matrix_diag).describe()

influence = model1.get_influence()
inf_sum = influence.summary_frame()

print(inf_sum.head())


student_resid = influence.resid_studentized_external
(cooks, p) = influence.cooks_distance
(dffits, p) = influence.dffits
leverage = influence.hat_matrix_diag




ARCres = pd.concat([df.articles, inf_sum], axis = 1)
ARC=ARCres.rename(columns={'hat_diag': 'leverage'})
ARCres.head()

ARCres[abs(ARCres.dffits) > 2 * math.sqrt(11 / 506)]

fig, axs = plt.subplots(3, 2, figsize=(20, 17), sharey=True)
axs[0, 0].scatter(ARCres.articles, ARCres.dfb_gender)
axs[0, 0].plot((0, 20), (0, 0), '-.r*')
axs[0,0].set_title("DFBetas for gender")
axs[0, 1].scatter(ARCres.articles, ARCres.dfb_married)
axs[0, 1].plot((0, 20), (0, 0), '-.r*')
axs[0,1].set_title("DFBetas for marital status")
axs[1, 0].scatter(ARCres.articles, ARCres.dfb_kids)
axs[1, 0].plot((0, 20), (0, 0), '-.r*')
axs[1,0].set_title("DFBetas for kids")
axs[1, 1].scatter(ARCres.articles, ARCres.dfb_prestige)
axs[1, 1].plot((0, 20), (0, 0), '-.r*')
axs[1,1].set_title("DFBetas for prestige")
axs[2, 0].scatter(ARCres.articles, ARCres.dfb_mentor)
axs[2, 0].plot((0, 20), (0, 0), '-.r*')
axs[2,0].set_title("DFBetas for mentor")

# standartizuotos liekanos
#obtain standardized residuals
standardized_residuals = influence.resid_studentized_internal

#display standardized residuals
print(standardized_residuals)

# neigiamas binominis
expr = """articles ~ gender + married + kids + prestige + mentor"""
y_train, X_train = dmatrices(expr, df, return_type = "dataframe")
nb_training_results = sm.GLM(y_train, X_train,family=sm.families.NegativeBinomial()).fit()
print(nb_training_results.summary())
print(nb_training_results.aic)

# ismetam prestige
expr = """articles ~ gender + married + kids + mentor"""
y_train, X_train = dmatrices(expr, df, return_type = "dataframe")
nb_training_results = sm.GLM(y_train, X_train,family=sm.families.NegativeBinomial()).fit()
print(nb_training_results.summary())
print(nb_training_results.aic)

# ismetam married
expr = """articles ~ gender + kids + mentor"""
y_train, X_train = dmatrices(expr, df, return_type = "dataframe")
nb_training_results = sm.GLM(y_train, X_train,family=sm.families.NegativeBinomial()).fit()
print(nb_training_results.summary())
print(nb_training_results.aic)

import math

# gender = 0.2633
print("Gender: ", round(math.exp(0.2633),2))

# married =  -0.1585
print("Married: ", round(math.exp(-0.1585),2))

# kids  =  -0.1268
print("Kids: ", round(math.exp(-0.1268),2))

# mentor = 0.0288
print("Mentor: ", round(math.exp(0.0288),2))

# pridedame saveika

expr = """articles ~ gender + married + kids + prestige + mentor + prestige*mentor"""
y_train, X_train = dmatrices(expr, df, return_type = "dataframe")
nb_training_results = sm.GLM(y_train, X_train,family=sm.families.NegativeBinomial()).fit()
print(nb_training_results.summary())
print(nb_training_results.aic)

# prognoze
model = sm.GLM(y_train,X_train,family=sm.families.NegativeBinomial())
model=model.fit()
model.summary()
results = pd.DataFrame({"observed":df["articles"],"pred":model.predict(X_train)})
print(results)